<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Robust Monocular Depth Estimation under Challenging Conditions, ICCV 2023">
  <meta name="keywords" content="depth estimation, challenging conditions, adverse weather, night, rain, snow, fog, self-supervised, monocular, supervised, adverse conditions, depth, ICCV 2023">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Robust Monocular Depth Estimation under Challenging Conditions</title>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PYXS918KCT"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PYXS918KCT');
</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
  <!-- style="background-color: rgb(240,240,240);"-->
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Robust Monocular Depth Estimation under Challenging Conditions</h1>

          <div class="is-size-4 publication-authors">
            <span class="author-block" style="padding-top:1.5rem; padding-bottom:1rem;">ICCV 2023</span>
          </div>
          
          <div class="is-size-5 publication-authors" style="padding-bottom:1rem">
            <span class="author-block">
              <a href="https://www.cs.cit.tum.de/camp/members/stefano-gasperini/">Stefano Gasperini</a><sup>*,1,2</sup></span>
            <span class="author-block">
              <a>Nils Morbitzer</a><sup>*,1</sup></span>
            </span>
            <span class="author-block">
              <a>HyunJun Jung</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://www.cs.cit.tum.de/camp/members/cv-nassir-navab/nassir-navab/">Nassir Navab</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://www.cs.cit.tum.de/camp/members/senior-research-scientists/federico-tombari/">Federico Tombari</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Technical University of Munich</span>
            <span class="author-block"><sup>2</sup> VisualAIs</span>
            <span class="author-block"><sup>3</sup> Google</span>
          </div>
          
          <div class="is-size-5 publication-authors" style="padding-bottom:1rem">
            <span class="author-block"><sup>*</sup> The authors contributed equally.</span>
          </div>
            
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!--span class="link-block">
                <a href="tbd_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>ICCV Paper</span>
                </a>
              </span-->
              <span class="link-block">
                <a href="tbd_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/md4all/md4all"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. 
              <span class="link-block">
                <a href="tbd_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video...</span>
                </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://forms.gle/31w2TvtTiVNyPb916"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Translated Images</span>
                  </a>
                </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top:1rem">
  <div class="container is-max-desktop" style="background-color: rgb(240,240,240);padding-top:4rem;padding-bottom:4rem">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-bottom:0.7rem">Can you see the trees?</h2>
        <div>
          <p>Hint: zoom in, increase the brightness, and look closely.</p>
        </div>
        <div class="">
          <img src="images/trees.png"></img>
        </div>
        <div>
          <p>Our model extracts robust features in all conditions, even in the dark.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top:0">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <!--div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths" style="padding-bottom:3rem">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           abstract tbd
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths" style="padding-bottom:3rem">
        <h2 class="title is-3">Motivation</h2>
        <div class="">
          <img src="images/factors.png"></img>
        </div>
        <p>
While state-of-the-art monocular depth estimation approaches achieve impressive results in ideal settings, they are highly unreliable under <b>challenging illumination and weather conditions</b>, such as at nighttime or in the presence of rain.
</br></br>
Noise, dark textureless areas, and reflections are detrimental factors that violate the training assumptions of both supervised and self-supervised methods.
While self-supervised works cannot establish the pixel correspondences needed to learn depth, 
supervised approaches learn artifacts from the ground truth sensor (LiDAR is shown in the figure above with samples from nuScenes).
        </p>
      </div>
    </div>
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths" style="padding-bottom:3rem">
        <h2 class="title is-3">Method</h2>
        <p>
Description coming soon.
        </p>
      </div>
    </div>
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths" style="padding-bottom:3rem">
        <h2 class="title is-3">Results</h2>
        <div class="">
          <img src="images/teaser.png"></img>
        </div>
        <p>
With md4all, we substantially outperform prior solutions delivering robust estimates in a variety of conditions.
Remarkably, the proposed md4all uses <b>a single monocular model</b> and no specialized branches.
</br></br>
The figure above shows predictions in challenging settings of the nuScenes dataset. The self-supervised Monodepth2 is unable to extract valuable features due to darkness and noise (top). The supervised AdaBins learns to mimic the sensor artifacts and predicts holes in the road (bottom). Applied on the same architectures, our md4all improves robustness in all conditions.
</br></br>
In our ICCV paper, we demonstrate the <b>effectiveness of md4all in standard and adverse conditions, under both types of supervision</b>, via extensive experiments on two public datasets, namely nuScenes and Oxford RobotCar.
        </p>
      </div>
    </div>
<!--Qualitative results on nuScenes between the fully-supervised AdaBins without and with our approach, and the self-supervised Monodepth2 without and with our method.-->
    <!-- Paper video. -->
    <!--div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths" style="padding-bottom:3rem">
        <h2 class="title is-3">Video</h2>
        <div class="">
          <!--iframe src="https://www.youtube.com/embed/LyugDwqfelQ?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe-->
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" style="padding-top:1.5rem;padding-bottom:6rem;" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre style="background-color: rgb(240,240,240);"><code>@inproceedings{gasperini_morbitzer2023md4all,
  title={Robust Monocular Depth Estimation under Challenging Conditions},
  author={Gasperini, Stefano and Morbitzer, Nils and Jung, HyunJun and Navab, Nassir and Tombari, Federico},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}
</code></pre>
  </div>
</section>


<footer class="footer" style="padding-bottom:3rem">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
